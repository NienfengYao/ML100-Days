{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cupoy 機器學習百日馬拉松-期末考](https://www.kaggle.com/c/ml100marathon-final-exam/)\n",
    "* Version\n",
    "  * V1: 使用 MobileNet 做 transfer learning\n",
    "  * V2: 使用 EarlyStopping/ReduceLROnPlateau，在 training 時依 val_loss 的情況來調整 learning rate.      \n",
    "* Score  \n",
    "\n",
    "| Version | Private Score |Public Score |  \n",
    "|------|------|------|\n",
    "|   V1  | 0.82600 | 0.83900 |\n",
    "|------|------|------|\n",
    "|   V2  | 0.82600 | 0.83900 |\n",
    "0.91600\n",
    "0.91900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version: V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_base = '/home/ryanyao/docker_mount/data/ml100marathon-final-exam'\n",
    "train_path = os.path.join(img_base, 'train')\n",
    "test_path = os.path.join(img_base, 'test')\n",
    "sub_train_path = os.path.join(img_base, 'sub_train')\n",
    "sub_valid_path = os.path.join(img_base, 'sub_valid')\n",
    "sub_test_path = os.path.join(img_base, 'sub_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dandelion', 'tulip', 'rose', 'sunflower', 'daisy']\n"
     ]
    }
   ],
   "source": [
    "class_set = os.listdir(train_path)\n",
    "print(class_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/dandelion/ images: 687\n",
      "train/tulip/ images: 633\n",
      "train/rose/ images: 515\n",
      "train/sunflower/ images: 488\n",
      "train/daisy/ images: 500\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks\n",
    "for i in class_set:\n",
    "    print('train/%s/ images:' %(i), len(os.listdir(os.path.join(train_path, i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy 各50張圖片到 sub_valid/sub_test, 其餘的 copy 到 sub_train\n",
    "def generate_dir():\n",
    "    for i_step in (sub_train_path, sub_valid_path, sub_test_path):\n",
    "        os.mkdir(i_step)\n",
    "        \n",
    "    for i_step in (sub_train_path, sub_valid_path, sub_test_path):\n",
    "        for i_class in class_set:\n",
    "            os.mkdir(os.path.join(i_step, i_class))\n",
    "            fnames = os.listdir(os.path.join(train_path, i_class))\n",
    "            \n",
    "            # sub_train dir\n",
    "            if (i_step == sub_train_path):\n",
    "                sub_fnames = fnames[:-100]\n",
    "            elif (i_step == sub_valid_path):\n",
    "                sub_fnames = fnames[-100:-50]\n",
    "            else:\n",
    "                sub_fnames = fnames[-50:]\n",
    "            for fname in sub_fnames:\n",
    "                src = os.path.join(train_path, i_class, fname)\n",
    "                det = os.path.join(i_step, i_class, fname)\n",
    "                # print(src)\n",
    "                # print(det)\n",
    "                shutil.copyfile(src, det)\n",
    "\n",
    "# generate_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround Issue: \"Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\"\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2323 images belonging to 5 classes.\n",
      "Found 250 images belonging to 5 classes.\n",
      "Found 250 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "sub_train_batches = ImageDataGenerator().flow_from_directory(sub_train_path, target_size=(224,224), batch_size=batch_size)\n",
    "sub_valid_batches = ImageDataGenerator().flow_from_directory(sub_valid_path, target_size=(224,224), batch_size=batch_size)\n",
    "sub_test_batches = ImageDataGenerator().flow_from_directory(sub_test_path, target_size=(224,224), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# 檢視 image input size\n",
    "print(sub_train_batches.image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ryanyao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanyao/anaconda3/lib/python3.7/site-packages/keras_applications/mobilenet.py:208: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "#imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "base_model = MobileNet(include_top=False) \n",
    "\n",
    "x = base_model.output\n",
    "# we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(1024, activation='relu')(x) \n",
    "x = Dense(100, activation='relu')(x)\n",
    "preds = Dense(5, activation='softmax')(x) # final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the model architecture\n",
    "# for i,layer in enumerate(model.layers):\n",
    "#     print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 3,331,869\n",
      "Trainable params: 3,309,981\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 輸出整個網路結構\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 EarlyStopping/ReduceLROnPlateau，在 training 時依 val_loss 的情況來調整 learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1)\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.3,min_lr=1e-12, monitor='val_loss', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ryanyao/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      " - 23s - loss: 0.6302 - acc: 0.7912 - val_loss: 1.1037 - val_acc: 0.7589\n",
      "Epoch 2/30\n",
      " - 19s - loss: 0.2693 - acc: 0.9081 - val_loss: 0.4348 - val_acc: 0.8807\n",
      "Epoch 3/30\n",
      " - 15s - loss: 0.1696 - acc: 0.9376 - val_loss: 0.9556 - val_acc: 0.7936\n",
      "Epoch 4/30\n",
      " - 14s - loss: 0.1842 - acc: 0.9410 - val_loss: 0.5743 - val_acc: 0.8440\n",
      "Epoch 5/30\n",
      " - 14s - loss: 0.1464 - acc: 0.9534 - val_loss: 0.7994 - val_acc: 0.8119\n",
      "Epoch 6/30\n",
      " - 13s - loss: 0.1097 - acc: 0.9650 - val_loss: 0.3718 - val_acc: 0.9128\n",
      "Epoch 7/30\n",
      " - 14s - loss: 0.0923 - acc: 0.9674 - val_loss: 0.5331 - val_acc: 0.8807\n",
      "Epoch 8/30\n",
      " - 13s - loss: 0.1289 - acc: 0.9560 - val_loss: 0.9298 - val_acc: 0.7982\n",
      "Epoch 9/30\n",
      " - 12s - loss: 0.1402 - acc: 0.9553 - val_loss: 0.6246 - val_acc: 0.8795\n",
      "Epoch 10/30\n",
      " - 15s - loss: 0.0902 - acc: 0.9702 - val_loss: 0.3288 - val_acc: 0.9083\n",
      "Epoch 11/30\n",
      " - 12s - loss: 0.0795 - acc: 0.9757 - val_loss: 0.4393 - val_acc: 0.8807\n",
      "Epoch 12/30\n",
      " - 12s - loss: 0.0541 - acc: 0.9805 - val_loss: 0.5562 - val_acc: 0.8761\n",
      "Epoch 13/30\n",
      " - 14s - loss: 0.0645 - acc: 0.9792 - val_loss: 0.8603 - val_acc: 0.8257\n",
      "Epoch 14/30\n",
      " - 14s - loss: 0.0818 - acc: 0.9774 - val_loss: 1.2223 - val_acc: 0.7982\n",
      "Epoch 15/30\n",
      " - 13s - loss: 0.0496 - acc: 0.9848 - val_loss: 0.4624 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 16/30\n",
      " - 13s - loss: 0.0243 - acc: 0.9939 - val_loss: 0.4535 - val_acc: 0.9174\n",
      "Epoch 17/30\n",
      " - 14s - loss: 0.0124 - acc: 0.9965 - val_loss: 0.3518 - val_acc: 0.9107\n",
      "Epoch 18/30\n",
      " - 15s - loss: 0.0066 - acc: 0.9983 - val_loss: 0.3341 - val_acc: 0.9404\n",
      "Epoch 19/30\n",
      " - 13s - loss: 0.0034 - acc: 0.9996 - val_loss: 0.3776 - val_acc: 0.9174\n",
      "Epoch 20/30\n",
      " - 14s - loss: 0.0021 - acc: 0.9996 - val_loss: 0.2779 - val_acc: 0.9450\n",
      "Epoch 21/30\n",
      " - 13s - loss: 0.0022 - acc: 0.9991 - val_loss: 0.3460 - val_acc: 0.9266\n",
      "Epoch 22/30\n",
      " - 12s - loss: 0.0018 - acc: 0.9996 - val_loss: 0.3185 - val_acc: 0.9404\n",
      "Epoch 23/30\n",
      " - 12s - loss: 0.0035 - acc: 0.9996 - val_loss: 0.2052 - val_acc: 0.9358\n",
      "Epoch 24/30\n",
      " - 12s - loss: 0.0037 - acc: 0.9987 - val_loss: 0.3122 - val_acc: 0.9358\n",
      "Epoch 25/30\n",
      " - 12s - loss: 7.4477e-04 - acc: 1.0000 - val_loss: 0.3310 - val_acc: 0.9196\n",
      "Epoch 26/30\n",
      " - 14s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2531 - val_acc: 0.9312\n",
      "Epoch 27/30\n",
      " - 13s - loss: 5.3151e-04 - acc: 1.0000 - val_loss: 0.2796 - val_acc: 0.9266\n",
      "Epoch 28/30\n",
      " - 12s - loss: 0.0017 - acc: 0.9996 - val_loss: 0.2383 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 29/30\n",
      " - 12s - loss: 0.0013 - acc: 0.9996 - val_loss: 0.4175 - val_acc: 0.9083\n",
      "Epoch 30/30\n",
      " - 13s - loss: 4.8434e-04 - acc: 1.0000 - val_loss: 0.2397 - val_acc: 0.9450\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "\n",
    "step_size_sub_train = sub_train_batches.n // sub_train_batches.batch_size\n",
    "step_size_sub_valid = sub_valid_batches.n // sub_valid_batches.batch_size\n",
    "history = model.fit_generator(generator=sub_train_batches, \n",
    "                    steps_per_epoch=step_size_sub_train, \n",
    "                    validation_data=sub_valid_batches,\n",
    "                    validation_steps=step_size_sub_valid,\n",
    "                    epochs=30,\n",
    "                    callbacks=[earlystop,reduce_lr],\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.340787940791675, 0.9241071428571429]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size_sub_test = sub_test_batches.n // sub_test_batches.batch_size\n",
    "model.evaluate_generator(generator=sub_test_batches, steps=step_size_sub_test, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上傳 Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}\n"
     ]
    }
   ],
   "source": [
    "print(sub_train_batches.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(columns=['id', 'flower_class'])\n",
    "fnames = os.listdir(test_path)\n",
    "\n",
    "for idx, fname in enumerate(fnames):\n",
    "    # Loads an image into PIL format.\n",
    "    img = image.load_img(os.path.join(test_path, fname), target_size=(224, 224))\n",
    "    \n",
    "    # Converts a PIL Image instance to a Numpy array. shape=(224, 224, 3)\n",
    "    img_data = image.img_to_array(img)   \n",
    "    \n",
    "    # Insert a new axis that will appear at the `axis` position in the expanded array shape. shape=(1, 224, 224, 3)\n",
    "    img_data = np.expand_dims(img_data, axis=0)                \n",
    "\n",
    "    preds = model.predict(img_data)\n",
    "    submit.loc[idx] = [fname.split('.')[0], preds.argmax()]\n",
    "\n",
    "submit.to_csv('Day101_submission_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
