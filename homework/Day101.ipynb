{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Cupoy 機器學習百日馬拉松-期末考](https://www.kaggle.com/c/ml100marathon-final-exam/)\n",
    "* Version\n",
    "  * V1: 使用 MobileNet 做 transfer learning\n",
    "  * V2: 使用 EarlyStopping/ReduceLROnPlateau，在 training 時依 val_loss 的情況來調整 learning rate.      \n",
    "  * V3: 調整最後的 FC layer，由二層調整為三層 (神經元個數也調大了)\n",
    "  * V4: 調整ImageDataGenerator 的參數，做了 rotate 與平移的設定\n",
    "* Score  \n",
    "\n",
    "| Version | Private Score |Public Score |  \n",
    "|------|------|------|\n",
    "|   V1  | 0.82600 | 0.83900 |\n",
    "|   V2  | 0.91600 | 0.91900 |\n",
    "|   V3  | 0.92200 | 0.92100 |\n",
    "|   V4  | 0.92500 | 0.94500 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version: V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_base = '/home/ryanyao/docker_mount/data/ml100marathon-final-exam'\n",
    "train_path = os.path.join(img_base, 'train')\n",
    "test_path = os.path.join(img_base, 'test')\n",
    "sub_train_path = os.path.join(img_base, 'sub_train')\n",
    "sub_valid_path = os.path.join(img_base, 'sub_valid')\n",
    "sub_test_path = os.path.join(img_base, 'sub_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dandelion', 'tulip', 'rose', 'sunflower', 'daisy']\n"
     ]
    }
   ],
   "source": [
    "class_set = os.listdir(train_path)\n",
    "print(class_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/dandelion/ images: 687\n",
      "train/tulip/ images: 633\n",
      "train/rose/ images: 515\n",
      "train/sunflower/ images: 488\n",
      "train/daisy/ images: 500\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks\n",
    "for i in class_set:\n",
    "    print('train/%s/ images:' %(i), len(os.listdir(os.path.join(train_path, i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy 各50張圖片到 sub_valid/sub_test, 其餘的 copy 到 sub_train\n",
    "def generate_dir():\n",
    "    for i_step in (sub_train_path, sub_valid_path, sub_test_path):\n",
    "        os.mkdir(i_step)\n",
    "        \n",
    "    for i_step in (sub_train_path, sub_valid_path, sub_test_path):\n",
    "        for i_class in class_set:\n",
    "            os.mkdir(os.path.join(i_step, i_class))\n",
    "            fnames = os.listdir(os.path.join(train_path, i_class))\n",
    "            \n",
    "            # sub_train dir\n",
    "            if (i_step == sub_train_path):\n",
    "                sub_fnames = fnames[:-100]\n",
    "            elif (i_step == sub_valid_path):\n",
    "                sub_fnames = fnames[-100:-50]\n",
    "            else:\n",
    "                sub_fnames = fnames[-50:]\n",
    "            for fname in sub_fnames:\n",
    "                src = os.path.join(train_path, i_class, fname)\n",
    "                det = os.path.join(i_step, i_class, fname)\n",
    "                # print(src)\n",
    "                # print(det)\n",
    "                shutil.copyfile(src, det)\n",
    "\n",
    "# generate_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround Issue: \"Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\"\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2323 images belonging to 5 classes.\n",
      "Found 250 images belonging to 5 classes.\n",
      "Found 250 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "sub_train_batches = datagen.flow_from_directory(sub_train_path, target_size=(224,224), batch_size=batch_size)\n",
    "sub_valid_batches = datagen.flow_from_directory(sub_valid_path, target_size=(224,224), batch_size=batch_size)\n",
    "sub_test_batches = datagen.flow_from_directory(sub_test_path, target_size=(224,224), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# 檢視 image input size\n",
    "print(sub_train_batches.image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下載 Keras NobileNet model 進行 transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ryanyao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanyao/anaconda3/lib/python3.7/site-packages/keras_applications/mobilenet.py:208: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "#imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "base_model = MobileNet(include_top=False, weights='imagenet') \n",
    "\n",
    "x = base_model.output\n",
    "# we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x) \n",
    "x = Dense(1024, activation='relu')(x)\n",
    "preds = Dense(5, activation='softmax')(x) # final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the model architecture\n",
    "# for i,layer in enumerate(model.layers):\n",
    "#     print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 5,333,189\n",
      "Trainable params: 5,311,301\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 輸出整個網路結構\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 EarlyStopping/ReduceLROnPlateau，在 training 時依 val_loss 的情況來調整 learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1)\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.3,min_lr=1e-12, monitor='val_loss', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ryanyao/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      " - 35s - loss: 0.7581 - acc: 0.7483 - val_loss: 2.5093 - val_acc: 0.5045\n",
      "Epoch 2/30\n",
      " - 22s - loss: 0.4261 - acc: 0.8581 - val_loss: 1.7696 - val_acc: 0.6606\n",
      "Epoch 3/30\n",
      " - 21s - loss: 0.3455 - acc: 0.8832 - val_loss: 0.8621 - val_acc: 0.7936\n",
      "Epoch 4/30\n",
      " - 21s - loss: 0.3601 - acc: 0.8863 - val_loss: 1.1866 - val_acc: 0.7110\n",
      "Epoch 5/30\n",
      " - 21s - loss: 0.2863 - acc: 0.9067 - val_loss: 0.3550 - val_acc: 0.9083\n",
      "Epoch 6/30\n",
      " - 21s - loss: 0.2651 - acc: 0.9123 - val_loss: 0.4181 - val_acc: 0.8532\n",
      "Epoch 7/30\n",
      " - 22s - loss: 0.2529 - acc: 0.9149 - val_loss: 0.5613 - val_acc: 0.8440\n",
      "Epoch 8/30\n",
      " - 22s - loss: 0.1978 - acc: 0.9324 - val_loss: 0.8761 - val_acc: 0.8119\n",
      "Epoch 9/30\n",
      " - 21s - loss: 0.2306 - acc: 0.9264 - val_loss: 0.6156 - val_acc: 0.8438\n",
      "Epoch 10/30\n",
      " - 21s - loss: 0.1846 - acc: 0.9408 - val_loss: 0.7637 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 11/30\n",
      " - 21s - loss: 0.1076 - acc: 0.9650 - val_loss: 0.4936 - val_acc: 0.8716\n",
      "Epoch 12/30\n",
      " - 21s - loss: 0.0488 - acc: 0.9834 - val_loss: 0.4786 - val_acc: 0.8853\n",
      "Epoch 13/30\n",
      " - 21s - loss: 0.0534 - acc: 0.9818 - val_loss: 0.2112 - val_acc: 0.9404\n",
      "Epoch 14/30\n",
      " - 21s - loss: 0.0580 - acc: 0.9792 - val_loss: 0.3299 - val_acc: 0.9037\n",
      "Epoch 15/30\n",
      " - 21s - loss: 0.0385 - acc: 0.9874 - val_loss: 0.4184 - val_acc: 0.9037\n",
      "Epoch 16/30\n",
      " - 22s - loss: 0.0291 - acc: 0.9918 - val_loss: 0.3581 - val_acc: 0.8991\n",
      "Epoch 17/30\n",
      " - 22s - loss: 0.0325 - acc: 0.9910 - val_loss: 0.3905 - val_acc: 0.9062\n",
      "Epoch 18/30\n",
      " - 21s - loss: 0.0188 - acc: 0.9939 - val_loss: 0.2527 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 19/30\n",
      " - 21s - loss: 0.0231 - acc: 0.9932 - val_loss: 0.3445 - val_acc: 0.9312\n",
      "Epoch 20/30\n",
      " - 22s - loss: 0.0181 - acc: 0.9948 - val_loss: 0.3145 - val_acc: 0.9128\n",
      "Epoch 21/30\n",
      " - 21s - loss: 0.0197 - acc: 0.9948 - val_loss: 0.2729 - val_acc: 0.9312\n",
      "Epoch 22/30\n",
      " - 22s - loss: 0.0058 - acc: 0.9987 - val_loss: 0.2895 - val_acc: 0.9404\n",
      "Epoch 23/30\n",
      " - 22s - loss: 0.0071 - acc: 0.9983 - val_loss: 0.2718 - val_acc: 0.9495\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "\n",
    "step_size_sub_train = sub_train_batches.n // sub_train_batches.batch_size\n",
    "step_size_sub_valid = sub_valid_batches.n // sub_valid_batches.batch_size\n",
    "history = model.fit_generator(generator=sub_train_batches, \n",
    "                    steps_per_epoch=step_size_sub_train, \n",
    "                    validation_data=sub_valid_batches,\n",
    "                    validation_steps=step_size_sub_valid,\n",
    "                    epochs=30,\n",
    "                    callbacks=[earlystop,reduce_lr],\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41266481046165737, 0.9241071428571429]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size_sub_test = sub_test_batches.n // sub_test_batches.batch_size\n",
    "model.evaluate_generator(generator=sub_test_batches, steps=step_size_sub_test, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上傳 Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}\n"
     ]
    }
   ],
   "source": [
    "print(sub_train_batches.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(columns=['id', 'flower_class'])\n",
    "fnames = os.listdir(test_path)\n",
    "\n",
    "for idx, fname in enumerate(fnames):\n",
    "    # Loads an image into PIL format.\n",
    "    img = image.load_img(os.path.join(test_path, fname), target_size=(224, 224))\n",
    "    \n",
    "    # Converts a PIL Image instance to a Numpy array. shape=(224, 224, 3)\n",
    "    img_data = image.img_to_array(img)   \n",
    "    \n",
    "    # Insert a new axis that will appear at the `axis` position in the expanded array shape. shape=(1, 224, 224, 3)\n",
    "    img_data = np.expand_dims(img_data, axis=0)                \n",
    "\n",
    "    preds = model.predict(img_data)\n",
    "    submit.loc[idx] = [fname.split('.')[0], preds.argmax()]\n",
    "\n",
    "submit.to_csv('Day101_submission_v4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
